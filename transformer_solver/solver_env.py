# transformer_solver/solver_env.py

import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from torchrl.data import Unbounded, UnboundedDiscrete, Composite
from typing import Optional, Dict, Union, Tuple, List

# --- í˜„ì¬ íŒ¨í‚¤ì§€(transformer_solver) ëª¨ë“ˆ ì„í¬íŠ¸ ---
from .definitions import (
    FEATURE_DIM, FEATURE_INDEX, SCALAR_PROMPT_FEATURE_DIM,
    NODE_TYPE_PADDING, NODE_TYPE_BATTERY, NODE_TYPE_LOAD, 
    NODE_TYPE_IC, NODE_TYPE_EMPTY
)
from .env_generator import PocatGenerator

# --- í™˜ê²½ ìƒìˆ˜ ---
BATTERY_NODE_IDX = 0 # ë°°í„°ë¦¬ ë…¸ë“œëŠ” í•­ìƒ 0ë²ˆ ì¸ë±ìŠ¤
REWARD_WEIGHT_ACTION = 0.0  # (A2C) ì•¡ì…˜(IC ìŠ¤í°) ì¦‰ì‹œ ë¹„ìš©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
REWARD_WEIGHT_PATH = 1.0    # (A2C) ê²½ë¡œ(Load->BATT) ì™„ì„± ì‹œ ëˆ„ì  ë¹„ìš© ê°€ì¤‘ì¹˜
STEP_PENALTY = 0.0          # (A2C) ìŠ¤í…ë‹¹ í˜ë„í‹°
FAILURE_PENALTY = -500.0    # (A2C) ì‹¤íŒ¨(ë§‰ë‹¤ë¥¸ ê¸¸) í˜ë„í‹°
PENALTY_WEIGHT_SLEEP = 1000.0 # (A2C) ì•”ì „ë¥˜ ì´ˆê³¼ í˜ë„í‹° ê°€ì¤‘ì¹˜


class PocatEnv(EnvBase):
    """
    Pocat ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•œ ê°•í™”í•™ìŠµ í™˜ê²½(Environment)ì…ë‹ˆë‹¤.
    
    TensorDictë¥¼ ìƒíƒœ(State)ë¡œ ì‚¬ìš©í•˜ë©°, Parameterized Action(Connect/Spawn)ì„
    ì²˜ë¦¬í•˜ì—¬ ìƒíƒœë¥¼ ì „ì´ì‹œí‚¤ê³  ë³´ìƒ(Reward)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    
    name = "pocat_env"

    def __init__(self, generator_params: dict, device: str = "cpu", N_max: int = 500, **kwargs):
        """
        PocatEnvë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            generator_params (dict): PocatGeneratorì— ì „ë‹¬ë  íŒŒë¼ë¯¸í„°
            device (str): í…ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•  ë””ë°”ì´ìŠ¤
            N_max (int): ëª¨ë¸ì´ ì²˜ë¦¬í•  ê³ ì •ëœ ìµœëŒ€ ë…¸ë“œ í¬ê¸°
        """
        super().__init__(device=device)
        
        # 1. N_max ê°’ì„ ì €ì¥í•©ë‹ˆë‹¤.
        self.N_max = N_max
        
        # 2. ì œë„ˆë ˆì´í„° ì´ˆê¸°í™” (N_max ì „ë‹¬)
        self.generator = PocatGenerator(**generator_params, N_max=N_max)
        
        # 3. ë§ˆìŠ¤í‚¹ ë° ê³„ì‚°ì— ì‚¬ìš©í•  ë²„í¼ ë“±ë¡
        self.register_buffer("arange_nodes", None, persistent=False)
        self.register_buffer("node_type_tensor", None, persistent=False)
        self.register_buffer("load_idx_tensor", None, persistent=False)
        self.register_buffer("rail_types", None, persistent=False)

        # 4. Observation, Action ìŠ¤í™ ì •ì˜
        self._make_spec()
        
        # 5. ì œì•½ì¡°ê±´(ì‹œí€€ì‹±, ë…ë¦½) ì •ë³´ ë¡œë“œ
        self._load_constraint_info()

    def _make_spec(self):
        """í™˜ê²½ì˜ Observation, Action, Reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        
        num_nodes = self.N_max
        
        # 1. Observation ìŠ¤í™ ì •ì˜
        self.observation_spec = Composite({
            # --- ì •ì  í…ì„œ (Generator ì œê³µ) ---
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM)),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,)),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes)),
            "connectivity_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "attention_mask": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            
            # --- ë™ì  í…ì„œ (Env ê´€ë¦¬) ---
            "adj_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "adj_matrix_T": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "unconnected_loads_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "trajectory_head": UnboundedDiscrete(shape=(1,)),
            "step_count": UnboundedDiscrete(shape=(1,)),
            "current_cost": Unbounded(shape=(1,)),
            "staging_cost": Unbounded(shape=(1,)), # í˜„ì¬ ê²½ë¡œì˜ ëˆ„ì  ë¹„ìš©
            "is_used_ic_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "current_target_load": UnboundedDiscrete(shape=(1,)),
            "is_exclusive_mask": Unbounded(shape=(num_nodes,), dtype=torch.long),
            "next_empty_slot_idx": UnboundedDiscrete(shape=(1,)), # ë‹¤ìŒ ìŠ¤í° ìœ„ì¹˜
        })
        
        # 2. Action ìŠ¤í™ ì •ì˜ (Parameterized Action)
        self.action_spec = Composite({
            # (0: Connect, 1: Spawn)
            "action_type": UnboundedDiscrete(shape=(1,)),
            # (0 ~ N_max-1): Connect ëŒ€ìƒ
            "connect_target": UnboundedDiscrete(shape=(1,)),
            # (0 ~ N_max-1): Spawní•  í…œí”Œë¦¿
            "spawn_template": UnboundedDiscrete(shape=(1,)),
        })
        
        # 3. Reward ìŠ¤í™ ì •ì˜
        self.reward_spec = Unbounded(shape=(1,))

    def _load_constraint_info(self):
        """
        config íŒŒì¼ì—ì„œ ì œì•½ì¡°ê±´ ì •ë³´ë¥¼ ë¡œë“œí•˜ê³ 
        ë§ˆìŠ¤í‚¹ì— ì‚¬ìš©í•˜ê¸° ì‰½ë„ë¡ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
        """
        # (B,L,IC) ìˆœì„œê°€ í…ì„œ ìˆœì„œì™€ ì¼ì¹˜
        self.node_name_to_idx = {name: i for i, name in enumerate(self.generator.config.node_names)}
        
        # 1. Independent Rail (ë…ë¦½ ë ˆì¼) ì •ë³´
        rail_type_map = {"exclusive_supplier": 1, "exclusive_path": 2}
        rail_types_list = []
        
        # (Load ë…¸ë“œëŠ” 1ë²ˆ ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘)
        load_start_idx = self.generator.num_battery
        for i, load_cfg in enumerate(self.generator.config.loads):
            load_idx = load_start_idx + i
            rail_type = rail_type_map.get(load_cfg.get("independent_rail_type"), 0)
            rail_types_list.append((load_idx, rail_type))
        
        # (N_max,) í¬ê¸°ì˜ í…ì„œë¡œ ë³€í™˜
        self.rail_types_tensor = torch.zeros(self.N_max, dtype=torch.long, device=self.device)
        if rail_types_list:
            indices = torch.tensor([idx for idx, _ in rail_types_list], dtype=torch.long, device=self.device)
            values = torch.tensor([val for _, val in rail_types_list], dtype=torch.long, device=self.device)
            self.rail_types_tensor.scatter_(0, indices, values)

        # 2. Power Sequence (ì „ì› ì‹œí€€ì‹±) ì •ë³´
        self.power_sequences = []
        for seq in self.generator.config.constraints.get("power_sequences", []):
            f_flag = seq.get("f", 1) # (1: ë™ì¼ ë¶€ëª¨ ê¸ˆì§€)
            j_idx = self.node_name_to_idx.get(seq['j'])
            k_idx = self.node_name_to_idx.get(seq['k'])
            if j_idx is not None and k_idx is not None:
                self.power_sequences.append((j_idx, k_idx, f_flag))

    def _ensure_buffers(self, td: TensorDict):
        """
        Observation í…ì„œê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤(ì£¼ë¡œ _reset ì‹œ)
        ë§ˆìŠ¤í‚¹ ê³„ì‚°ì— í•„ìš”í•œ í—¬í¼ í…ì„œë“¤ì„ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        num_nodes = td["nodes"].shape[1] # (N_max)

        if self.arange_nodes is None or self.arange_nodes.numel() != num_nodes:
            self.arange_nodes = torch.arange(num_nodes, device=self.device)
        
        if self.node_type_tensor is None:
            # (N_max,)
            node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
            self.node_type_tensor = node_types
            
            # (N_loads,)
            self.load_idx_tensor = torch.where(node_types == NODE_TYPE_LOAD)[0]

    def select_start_nodes(self, td: TensorDict) -> Tuple[int, torch.Tensor]:
        """ POMO (Multi-Start)ë¥¼ ìœ„í•´ ì‹œì‘ ê°€ëŠ¥í•œ ëª¨ë“  Load ë…¸ë“œì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
        self._ensure_buffers(td) # load_idx_tensor ìµœì‹ í™”
        return len(self.load_idx_tensor), self.load_idx_tensor

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        """ í™˜ê²½ì„ ì´ˆê¸° ìƒíƒœ(State)ë¡œ ë¦¬ì…‹í•©ë‹ˆë‹¤. """
        
        batch_size = kwargs.get("batch_size", self.batch_size)
        if td is None:
            if isinstance(batch_size, tuple): batch_size = batch_size[0]
            td_initial = self.generator(batch_size=batch_size).to(self.device)
        else:
            td_initial = td
            batch_size = td_initial.batch_size[0]

        num_nodes = self.N_max

        # --- 1. ë™ì  ìƒíƒœ í…ì„œ ì´ˆê¸°í™” ---
        
        # adj_matrix: (B, N_max, N_max) - ì‹¤ì œ ì—°ê²°ëœ ì—£ì§€ (ëª¨ë‘ 0)
        adj_matrix = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)
        adj_matrix_T = torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device)

        # is_active_mask: (B, N_max) - í˜„ì¬ í™œì„±í™”ëœ ë…¸ë“œ (ì •ì  í”¼ì²˜ì—ì„œ ë³µì‚¬)
        is_active_mask = td_initial["nodes"][..., FEATURE_INDEX["is_active"]].bool()
        # (ì •ì  í”¼ì²˜ì—ì„œ ë™ì  ë§ˆìŠ¤í¬ë¡œ ë³µì‚¬)
        is_template_mask = td_initial["nodes"][..., FEATURE_INDEX["is_template"]].bool()
        can_spawn_into_mask = td_initial["nodes"][..., FEATURE_INDEX["can_spawn_into"]].bool()

        # unconnected_loads_mask: (B, N_max) - ì•„ì§ ì—°ê²° ì•ˆ ëœ ë¡œë“œ
        node_types = td_initial["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        unconnected_loads_mask = (node_types == NODE_TYPE_LOAD).unsqueeze(0).expand(batch_size, -1)
        
        # next_empty_slot_idx: (B, 1) - ë‹¤ìŒ ìŠ¤í° ìœ„ì¹˜ (BATT+LOADS+TEMPLATES ê°œìˆ˜)
        next_empty_slot_idx = torch.full((batch_size, 1), self.generator.num_components, dtype=torch.long, device=self.device)

        # 2. TensorDict ìƒì„±
        reset_td = TensorDict({
            # ì •ì  í…ì„œ (Generatorë¡œë¶€í„° ë³µì‚¬)
            "nodes": td_initial["nodes"].clone(),
            "scalar_prompt_features": td_initial["scalar_prompt_features"],
            "matrix_prompt_features": td_initial["matrix_prompt_features"],
            "connectivity_matrix": td_initial["connectivity_matrix"],
            "attention_mask": td_initial["attention_mask"],
            
            # ë™ì  í…ì„œ (ì´ˆê¸°í™”)
            "adj_matrix": adj_matrix,
            "adj_matrix_T": adj_matrix_T,
            "unconnected_loads_mask": unconnected_loads_mask,
            "is_active_mask": is_active_mask,
            "is_template_mask": is_template_mask,
            "can_spawn_into_mask": can_spawn_into_mask,
            "next_empty_slot_idx": next_empty_slot_idx,
            "trajectory_head": torch.full((batch_size, 1), BATTERY_NODE_IDX, dtype=torch.long, device=self.device),
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            "current_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "staging_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "is_used_ic_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "current_target_load": torch.full((batch_size, 1), -1, dtype=torch.long, device=self.device),
            "is_exclusive_mask": torch.zeros(batch_size, num_nodes, dtype=torch.long, device=self.device),
            "done": torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device),
        }, batch_size=[batch_size], device=self.device)
       
        self._ensure_buffers(reset_td)
        return reset_td

    def step(self, tensordict: TensorDict) -> TensorDict:
        """ _stepì„ í˜¸ì¶œ (torchrl EnvBase í˜¸í™˜ìš©) """
        return self._step(tensordict)

    def _step(self, td: TensorDict) -> TensorDict:
        """
        ëª¨ë¸ì´ ê²°ì •í•œ Parameterized Actionì„ ì‹¤í–‰í•˜ì—¬
        í™˜ê²½ì˜ ìƒíƒœ(State)ë¥¼ ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì „ì´ì‹œí‚µë‹ˆë‹¤.
        
        - (ì•¡ì…˜ íƒ€ì… 0: Connect) -> ê¸°ì¡´ í™œì„± ë…¸ë“œì— ì—°ê²°
        - (ì•¡ì…˜ íƒ€ì… 1: Spawn)   -> í…œí”Œë¦¿ì„ Empty ìŠ¬ë¡¯ì— ë³µì‚¬(Spawn) í›„ ì—°ê²°
        """
        batch_size, num_nodes = td["nodes"].shape[0], self.N_max
        action_dict = td["action"]
        
        # (B,)
        action_type = action_dict["action_type"].squeeze(-1)
        connect_target = action_dict["connect_target"].squeeze(-1)
        spawn_template = action_dict["spawn_template"].squeeze(-1)
        
        current_head = td["trajectory_head"].clone().squeeze(-1) # (B,)

        # --- 0. ì´ë¯¸ 'done'ì¸ ë°°ì¹˜ëŠ” ë¬´ì‹œ ---
        is_already_done = td["done"].squeeze(-1)
        if is_already_done.all():
            return TensorDict({
                "next": td, 
                "reward": torch.zeros(batch_size, 1, device=self.device), 
                "done": td["done"]}, batch_size=td.batch_size)

        # --- 1. ìƒíƒœ í…ì„œ ë³µì œ (ìˆ˜ì • ì¤€ë¹„) ---
        next_obs = td.clone(recurse=False)
        # (In-place ìˆ˜ì •ì´ ë°œìƒí•˜ëŠ” ë™ì  í…ì„œë“¤ì€ ëª¨ë‘ ê¹Šì€ ë³µì‚¬)
        next_obs["nodes"] = td["nodes"].clone() # (ê°€ì¥ ì¤‘ìš”)
        next_obs["adj_matrix"] = td["adj_matrix"].clone()
        next_obs["adj_matrix_T"] = td["adj_matrix_T"].clone()
        next_obs["connectivity_matrix"] = td["connectivity_matrix"].clone()
        next_obs["is_active_mask"] = td["is_active_mask"].clone()
        next_obs["is_template_mask"] = td["is_template_mask"].clone()
        next_obs["can_spawn_into_mask"] = td["can_spawn_into_mask"].clone()
        next_obs["current_target_load"] = td["current_target_load"].clone()
        next_obs["is_exclusive_mask"] = td["is_exclusive_mask"].clone()
        next_obs["staging_cost"] = td["staging_cost"].clone()
        next_obs["is_used_ic_mask"] = td["is_used_ic_mask"].clone()
        next_obs["adj_matrix_T"] = td["adj_matrix_T"].clone()
        next_obs["trajectory_head"] = td["trajectory_head"].clone()
        next_obs["unconnected_loads_mask"] = td["unconnected_loads_mask"].clone()
        next_obs["current_cost"] = td["current_cost"].clone()
        next_obs["next_empty_slot_idx"] = td["next_empty_slot_idx"].clone()

        step_reward = torch.full((batch_size,), STEP_PENALTY, dtype=torch.float32, device=self.device)
        batch_indices = torch.arange(batch_size, device=self.device)

        # --- 2. ì•¡ì…˜ íƒ€ì… ë¶„ê¸° ---
        
        # --- 2a. [Select New Load] ---
        # (í˜„ì¬ í—¤ë“œê°€ ë°°í„°ë¦¬ì¼ ë•Œ)
        head_is_battery = (current_head == BATTERY_NODE_IDX)
        if head_is_battery.any():
            # 'Select New Load' ì•¡ì…˜ì€ 'Connect' ì•¡ì…˜ìœ¼ë¡œ ì „ë‹¬ë¨
            b_idx_batt = batch_indices[head_is_battery]
            selected_load = connect_target[head_is_battery]

            is_load_selection = (selected_load != BATTERY_NODE_IDX)
            if is_load_selection.any():
                load_rows = b_idx_batt[is_load_selection]
                load_node_idx = selected_load[is_load_selection]
                
                # Headë¥¼ ì„ íƒëœ Loadë¡œ ì´ë™
                next_obs["trajectory_head"][load_rows, 0] = load_node_idx
                # 'ì—°ê²° ì•ˆ ë¨' ë§ˆìŠ¤í¬ì—ì„œ ì œê±°
                next_obs["unconnected_loads_mask"][load_rows, load_node_idx] = False
                # í˜„ì¬ ê²½ë¡œì˜ ìµœì¢… íƒ€ê²Ÿìœ¼ë¡œ ì„¤ì •
                next_obs["current_target_load"][load_rows, 0] = load_node_idx
                # ê²½ë¡œ ë¹„ìš© ì´ˆê¸°í™”
                next_obs["staging_cost"][load_rows] = 0.0
                
                # 'ë…ë¦½ ë ˆì¼' ìƒíƒœ ì „íŒŒ ì‹œì‘
                # (B_load,)
                rail_status = self.rail_types_tensor[load_node_idx]
                next_obs["is_exclusive_mask"][load_rows, load_node_idx] = rail_status

        # --- 2b. [Find Parent / Spawn] ---
        # (í˜„ì¬ í—¤ë“œê°€ Load ë˜ëŠ” ICì¼ ë•Œ)
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = batch_indices[head_is_node]
            child_node = current_head[head_is_node] # (B_node,)
            
            # (B_node,)
            is_connect = (action_type[head_is_node] == 0)
            is_spawn = ~is_connect
            
            # (B_node,) - ìµœì¢… ë¶€ëª¨ê°€ ë  ë…¸ë“œì˜ ì¸ë±ìŠ¤
            parent_node = torch.zeros_like(child_node)
            
            # --- Connect ì•¡ì…˜ ì²˜ë¦¬ ---
            if is_connect.any():
                b_idx_connect = b_idx_node[is_connect]
                # 'Connect' í—¤ë“œì—ì„œ ë¶€ëª¨ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                parent_connect = connect_target[b_idx_connect]
                parent_node[is_connect] = parent_connect
            
            # --- Spawn ì•¡ì…˜ ì²˜ë¦¬ ---
            if is_spawn.any():
                b_idx_spawn = b_idx_node[is_spawn]
                child_spawn = child_node[is_spawn]
                
                # 'Spawn' í—¤ë“œì—ì„œ í…œí”Œë¦¿ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                template_idx = spawn_template[b_idx_spawn] # (B_spawn,)
                # ìŠ¤í°ë  ë¹ˆ ìŠ¬ë¡¯ ì¸ë±ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                slot_idx = next_obs["next_empty_slot_idx"][b_idx_spawn].squeeze(-1) # (B_spawn,)
                
                # 1. Spawn: í…œí”Œë¦¿ í”¼ì²˜ -> ë¹ˆ ìŠ¬ë¡¯ìœ¼ë¡œ ë³µì‚¬
                template_features = next_obs["nodes"][b_idx_spawn, template_idx]
                next_obs["nodes"][b_idx_spawn, slot_idx] = template_features.detach()

                # Spawnëœ ìŠ¬ë¡¯ì€ í…œí”Œë¦¿ê³¼ ë™ì¼í•œ ì „ì•• í˜¸í™˜ì„±ì„ ê°€ì ¸ì•¼ í•˜ë¯€ë¡œ
                # connectivity_matrixì˜ í–‰/ì—´ì„ í…œí”Œë¦¿ì—ì„œ ë³µì‚¬í•œë‹¤.
                connectivity_matrix = next_obs["connectivity_matrix"]
                connectivity_matrix[b_idx_spawn, :, slot_idx] = connectivity_matrix[b_idx_spawn, :, template_idx]
                connectivity_matrix[b_idx_spawn, slot_idx, :] = connectivity_matrix[b_idx_spawn, template_idx, :]

                # 2. ìƒíƒœ ë³€ê²½: (Template -> Active)
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["is_active"]] = 1.0
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["is_template"]] = 0.0
                next_obs["nodes"][b_idx_spawn, slot_idx, FEATURE_INDEX["can_spawn_into"]] = 0.0
                
                # 3. í™˜ê²½ ë™ì  ë§ˆìŠ¤í¬ ì—…ë°ì´íŠ¸
                next_obs["is_active_mask"][b_idx_spawn, slot_idx] = True
                next_obs["is_template_mask"][b_idx_spawn, slot_idx] = False
                next_obs["can_spawn_into_mask"][b_idx_spawn, slot_idx] = False

                # 4. ë‹¤ìŒ ë¹ˆ ìŠ¬ë¡¯ ì¸ë±ìŠ¤ +1
                next_obs["next_empty_slot_idx"][b_idx_spawn] += 1
                
                # 5. ìŠ¤í° ë¹„ìš©(cost) ì¦‰ì‹œ ë°˜ì˜
                template_cost = next_obs["nodes"][b_idx_spawn, template_idx, FEATURE_INDEX["cost"]]
                staging_cost_increase = template_cost.unsqueeze(-1) # (B_spawn, 1)
                
                # staging_cost ë° current_costì— ìŠ¤í° ë¹„ìš© ì¶”ê°€
                next_obs["staging_cost"][b_idx_spawn] += staging_cost_increase
                next_obs["current_cost"][b_idx_spawn] += staging_cost_increase
                
                # R_action ë³´ìƒ (ìŠ¤í° ì¦‰ì‹œ)
                step_reward[b_idx_spawn] += REWARD_WEIGHT_ACTION * (-staging_cost_increase.squeeze(-1))
                
                # 'is_used_ic_mask'ì— í…œí”Œë¦¿ ì¸ë±ìŠ¤ ëŒ€ì‹  *ìŠ¤í°ëœ ìŠ¬ë¡¯ ì¸ë±ìŠ¤*ë¥¼ ê¸°ë¡
                next_obs["is_used_ic_mask"][b_idx_spawn, slot_idx] = True
                
                # 6. ìµœì¢… ë¶€ëª¨ë¥¼ 'ìŠ¤í°ëœ ìŠ¬ë¡¯'ìœ¼ë¡œ ì„¤ì •
                parent_node[is_spawn] = slot_idx

            # --- 3. ê³µí†µ ì—°ê²° ë¡œì§ (Connect/Spawn ê³µí†µ) ---
            
            # 3a. ì—£ì§€ ì¶”ê°€: (parent_node) -> (child_node)
            next_obs["adj_matrix"][b_idx_node, parent_node, child_node] = True
            # (Tì—ë„ ì—£ì§€ ì¶”ê°€: (child_node) -> (parent_node))
            next_obs["adj_matrix_T"][b_idx_node, child_node, parent_node] = True

            # 3b. 'ë…ë¦½ ë ˆì¼' ìƒíƒœ ì „íŒŒ (ìì‹ -> ë¶€ëª¨)
            child_status = next_obs["is_exclusive_mask"][b_idx_node, child_node] # (B_node,)
            if (child_status > 0).any():
                parent_status = next_obs["is_exclusive_mask"][b_idx_node, parent_node]
                
                # 'Path'(2)ëŠ” ICë¥¼ íƒ€ê³  ê³„ì† ì „íŒŒë¨
                status_to_propagate = torch.where(
                    child_status == 2, 
                    child_status, 
                    torch.tensor(0, device=self.device, dtype=torch.long)
                )
                
                # 'Supplier'(1)ëŠ” Loadì—ì„œ ì‹œì‘í•  ë•Œë§Œ ì „íŒŒë¨
                is_child_load = (self.node_type_tensor[child_node] == NODE_TYPE_LOAD)
                status_from_supplier = torch.where(
                    (child_status == 1) & is_child_load,
                    child_status,
                    torch.tensor(0, device=self.device, dtype=torch.long)
                )
                
                status_from_child = torch.max(status_to_propagate, status_from_supplier)
                new_parent_status = torch.max(parent_status, status_from_child)
                next_obs["is_exclusive_mask"][b_idx_node, parent_node] = new_parent_status

            # 3c. ë‹¤ìŒ Head ì„¤ì •
            parent_is_battery = (parent_node == BATTERY_NODE_IDX)
            
            # í—¤ë“œ(parent_node)ê°€ ì´ë¯¸ ë¶€ëª¨ë¥¼ ê°€ì¡ŒëŠ”ì§€ í™•ì¸
            # adj_matrix_T[b, node, :]ê°€ 1ì´ë¼ë„ ìˆìœ¼ë©´, nodeëŠ” ì´ë¯¸ ë¶€ëª¨ê°€ ìˆìŒ
            parent_already_has_parent = next_obs["adj_matrix_T"][b_idx_node, parent_node].any(dim=-1)
            
            # ë°°í„°ë¦¬ì— ë„ë‹¬í•˜ê±°ë‚˜, ì´ë¯¸ ì—°ê²°ëœ ë…¸ë“œì— ë„ë‹¬í•˜ë©´ ê²½ë¡œ ì™„ì„±
            path_is_finished = parent_is_battery | parent_already_has_parent

            next_obs["trajectory_head"][b_idx_node, 0] = torch.where(
                path_is_finished,  # ğŸ’¡ ì¡°ê±´ ë³€ê²½
                BATTERY_NODE_IDX,  # ê²½ë¡œê°€ ëë‚¬ìœ¼ë©´ ë°°í„°ë¦¬ë¡œ ë³µê·€
                parent_node        # ì•„ë‹ˆë©´ ê²½ë¡œ ì¶”ì  ê³„ì†
            )
            
            # 3d. ê²½ë¡œ ì™„ì„± (R_path ë³´ìƒ)
            if parent_is_battery.any():
                finished_rows = b_idx_node[parent_is_battery]
                
                # ê²½ë¡œ ì™„ì„± ì‹œ, ëˆ„ì ëœ staging_costë¥¼ R_path ë³´ìƒìœ¼ë¡œ ì¶”ê°€
                sub_trajectory_total_cost = next_obs["staging_cost"][finished_rows]
                step_reward[finished_rows] += REWARD_WEIGHT_PATH * (-sub_trajectory_total_cost.squeeze(-1))
                
                # staging_cost ë¦¬ì…‹
                next_obs["staging_cost"][finished_rows] = 0.0
                next_obs["current_target_load"][finished_rows, 0] = -1

        # --- 4. ì „ë ¥/ë°œì—´ ì¬ê³„ì‚° (ì—°ì‚° ë¹„ìš© ë†’ìŒ) ---
        # (ëª¨ë“  ë°°ì¹˜ê°€ ìµœì†Œ 1ìŠ¤í… ì´ìƒ ì§„í–‰í–ˆì„ ë•Œë§Œ ê³„ì‚°)
        if td["step_count"].min() > 0 or head_is_node.any():
            final_i_out, power_loss, new_temp = self._calculate_tree_loads(
                next_obs["nodes"], 
                next_obs["adj_matrix"],
                next_obs["adj_matrix_T"] # ğŸ’¡ adj_matrix_T ì „ë‹¬
            )
            next_obs["nodes"][..., FEATURE_INDEX["current_out"]] = final_i_out
            next_obs["nodes"][..., FEATURE_INDEX["junction_temp"]] = new_temp
        
        next_obs.set("step_count", td["step_count"] + 1)

        # --- 5. ì¢…ë£Œ ì¡°ê±´ í™•ì¸ ---
        # (get_action_maskê°€ 3ì¢… ë§ˆìŠ¤í¬ë¥¼ ëª¨ë‘ ë°˜í™˜í•œë‹¤ê³  ê°€ì •)
        next_masks = self.get_action_mask(next_obs)
        # Connect/Spawn ë‘˜ ë‹¤ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
        is_stuck = ~(next_masks["mask_type"].any(dim=-1))
        
        all_loads_connected = (next_obs["unconnected_loads_mask"].sum(dim=1) == 0)
        trajectory_finished = (next_obs["trajectory_head"].squeeze(-1) == BATTERY_NODE_IDX)
        
        done_successfully = all_loads_connected & trajectory_finished
        max_steps = 2 * self.N_max # ìµœëŒ€ ìŠ¤í… ì œí•œ
        timed_out = (next_obs["step_count"] > max_steps).squeeze(-1)
        
        is_done = done_successfully | timed_out | is_stuck
        next_obs["done"] = is_done.unsqueeze(-1)

        # --- 6. ìµœì¢… ë³´ìƒ ê³„ì‚° ---
        final_reward = self.get_reward(
            next_obs,
            step_reward, # (STEP_PENALTY + R_action + R_path)
            done_successfully,
            timed_out,
            is_stuck
        )
        
        # ì´ë¯¸ 'done'ì´ì—ˆë˜ ìƒ˜í”Œì€ ë³´ìƒ 0, ìƒíƒœ ë¡¤ë°±
        if is_already_done.any():
            final_reward[is_already_done] = 0.0
            next_obs[is_already_done] = td[is_already_done]

        return TensorDict({
            "next": next_obs,
            "reward": final_reward.unsqueeze(-1),
            "done": next_obs["done"],
        }, batch_size=batch_size)
        
    def get_reward(self,
                   td: TensorDict,
                   step_reward: torch.Tensor,
                   done_successfully: torch.Tensor,
                   timed_out: torch.Tensor,
                   is_stuck: torch.Tensor) -> torch.Tensor:
        """
        ìµœì¢… ìŠ¤í… ë³´ìƒì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        (ê¸°ë³¸ ìŠ¤í… ë³´ìƒ + ì„±ê³µ ì‹œ ì•”ì „ë¥˜ í˜ë„í‹° or ì‹¤íŒ¨ ì‹œ í˜ë„í‹°)
        """
        reward = step_reward.clone()

        # 1. ì„±ê³µí•œ ê²½ìš°: ì•”ì „ë¥˜ ì œì•½ ê²€ì‚¬
        if done_successfully.any():
            td_success = td[done_successfully]
            
            total_sleep_current = self._calculate_total_sleep_current(td_success)
            
            # (ìŠ¤ì¹¼ë¼ í”„ë¡¬í”„íŠ¸ 1ë²ˆ ì¸ë±ìŠ¤ = max_sleep_current)
            max_sleep_current = td_success["scalar_prompt_features"][:, 1]
            
            # Hinge Loss: ì´ˆê³¼í•œ ë§Œí¼ë§Œ í˜ë„í‹° ì ìš©
            violation_amount = total_sleep_current - max_sleep_current
            hinge_violation = torch.relu(violation_amount)
            
            sleep_penalty = PENALTY_WEIGHT_SLEEP * hinge_violation
            
            # rewardì— í˜ë„í‹° ì°¨ê°
            reward[done_successfully] -= sleep_penalty

        # 2. ì‹¤íŒ¨í•œ ê²½ìš°: ê³ ì • í˜ë„í‹°
        failed = (timed_out | is_stuck) & ~done_successfully
        if failed.any():
            reward[failed] = FAILURE_PENALTY
            
        return reward

    # ---
    # ì„¹ì…˜ 5: ì•¡ì…˜ ë§ˆìŠ¤í‚¹ (ì—°ì‚° ì§‘ì•½ì )
    # ---
    
    def get_action_mask(self, td: TensorDict, debug: bool = False) -> Dict[str, torch.Tensor]:
        """
        í˜„ì¬ ìƒíƒœ(td)ì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ì•¡ì…˜ì„ ê³„ì‚°í•˜ì—¬
        3ì¢…ë¥˜ì˜ ë§ˆìŠ¤í¬ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            {
                "mask_type": (B, 2) - [Can_Connect, Can_Spawn]
                "mask_connect": (B, N_max) - ì—°ê²° ê°€ëŠ¥í•œ ë¶€ëª¨(Active)
                "mask_spawn": (B, N_max) - ìŠ¤í° ê°€ëŠ¥í•œ í…œí”Œë¦¿(Template)
            }
        """
        self._ensure_buffers(td) # ë²„í¼ ìµœì‹ í™”

        batch_size, num_nodes = td.batch_size[0], self.N_max
        current_head = td["trajectory_head"].clone().squeeze(-1) # (B,)

        # --- 1. ê¸°ë³¸ ìƒíƒœ ë§ˆìŠ¤í¬ (ì €ë¹„ìš©) ---
        is_active = td["is_active_mask"] # (B, N_max) - í˜„ì¬ í™œì„± ë…¸ë“œ
        is_template = td["is_template_mask"] # (B, N_max) - í…œí”Œë¦¿ ë…¸ë“œ
        
        # --- 2. [Select New Load] ëª¨ë“œ ë§ˆìŠ¤í‚¹ ---
        head_is_battery = (current_head == BATTERY_NODE_IDX)
        if debug:
            reasons = {}

        # (B, 2)
        mask_type = torch.zeros(batch_size, 2, dtype=torch.bool, device=self.device)
        # (B, N_max)
        mask_connect = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)
        # (B, N_max)
        mask_spawn = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)

        if head_is_battery.any():
            b_idx_batt = torch.where(head_is_battery)[0]
            
            # ë°°í„°ë¦¬ì—ì„œëŠ” 'Connect'ë§Œ ê°€ëŠ¥
            mask_type[b_idx_batt, 0] = True 
            
            # 'Connect' ëŒ€ìƒì€ 'unconnected_loads_mask'
            mask_connect[b_idx_batt] = td["unconnected_loads_mask"][b_idx_batt]
            
            # ë§Œì•½ ëª¨ë“  ë¡œë“œê°€ ì—°ê²°ë˜ì—ˆìœ¼ë©´ (unconnected.sum() == 0),
            # 'BATTERY_NODE_IDX' (0ë²ˆ)ì— ì—°ê²°í•˜ì—¬ ì¢…ë£Œ ì‹ í˜¸
            all_connected = (td["unconnected_loads_mask"][b_idx_batt].sum(dim=-1) == 0)
            if all_connected.any():
                b_idx_finish = b_idx_batt[all_connected]
                mask_connect[b_idx_finish, BATTERY_NODE_IDX] = True
        
            if debug:
                reasons["mask_type"] = mask_type[b_idx_batt]
                reasons["mask_connect"] = mask_connect[b_idx_batt]

        # --- 3. [Find Parent / Spawn] ëª¨ë“œ ë§ˆìŠ¤í‚¹ (ê³ ë¹„ìš©) ---
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = torch.where(head_is_node)[0]
            child_nodes = current_head[b_idx_node] # (B_node,)
            B_act = len(b_idx_node) # ì‹¤ì œ ì—°ì‚°í•  ë°°ì¹˜ í¬ê¸°
            
            # --- 3a. ì €ë¹„ìš© ë§ˆìŠ¤í¬ (ì „ì••, ì‚¬ì´í´, ë…ë¦½, ì‹œí€€ì‹±) ---
            
            # (B_act, N_max)
            connectivity = td["connectivity_matrix"][b_idx_node]
            volt_ok = connectivity[torch.arange(B_act), :, child_nodes]
            
            # (B_act, N_max)
            path_mask = self._trace_path_batch(child_nodes, td["adj_matrix_T"][b_idx_node])
            cycle_ok = ~path_mask            


            # (B_act, N_max)
            exclusive_ok = self._get_exclusive_mask(
                td,           # ğŸ’¡ 'td' ì „ë‹¬
                b_idx_node,   # ğŸ’¡ 'b_idx_node' ì „ë‹¬
                child_nodes
            )
            
            # (B_act, N_max)
            power_seq_ok = self._get_power_sequence_mask(
                td["adj_matrix"][b_idx_node],
                child_nodes,
                td,           
                b_idx_node    
            )
            
            # (B_act, N_max) - ëª¨ë“  ì €ë¹„ìš© ì œì•½ì„ í†µê³¼í•œ í›„ë³´
            base_valid_parents = volt_ok & cycle_ok & exclusive_ok & power_seq_ok
            
            # --- 3b. ê³ ë¹„ìš© ë§ˆìŠ¤í¬ (ì „ë¥˜/ë°œì—´ ì‹œë®¬ë ˆì´ì…˜) ---
            
            # (B_act, N_max) - ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ê²€ì¦ëœ ìµœì¢… ìœ íš¨ ë¶€ëª¨
            thermal_current_ok = self._get_thermal_current_mask(
                td,
                b_idx_node,
                child_nodes,
                base_valid_parents # ì‹œë®¬ë ˆì´ì…˜ ëŒ€ìƒì„ ì¤„ì´ê¸° ìœ„í•´ ì €ë¹„ìš© ë§ˆìŠ¤í¬ ì „ë‹¬
            )
            
            final_valid_parents = base_valid_parents & thermal_current_ok
            
            # --- 3c. ìµœì¢… 3ì¢… ë§ˆìŠ¤í¬ ìƒì„± ---
            
            # 'Connect' ëŒ€ìƒ: ìµœì¢… ìœ íš¨ ë¶€ëª¨ + 'Active' ìƒíƒœ
            mask_connect[b_idx_node] = final_valid_parents & is_active[b_idx_node]
            
            # 'Spawn' ëŒ€ìƒ: ìµœì¢… ìœ íš¨ ë¶€ëª¨ + 'Template' ìƒíƒœ
            mask_spawn[b_idx_node] = final_valid_parents & is_template[b_idx_node]
            
            # 'Type' ë§ˆìŠ¤í¬
            can_connect = mask_connect[b_idx_node].any(dim=-1) # (B_node,)
            
            # (ìŠ¤í°ì€ ë¹ˆ ìŠ¬ë¡¯ì´ ë‚¨ì•„ìˆì–´ì•¼ ê°€ëŠ¥)
            has_empty_slots = (td["next_empty_slot_idx"][b_idx_node] < self.N_max)
            can_spawn = mask_spawn[b_idx_node].any(dim=-1) & has_empty_slots.squeeze(-1)
            
            mask_type[b_idx_node, 0] = can_connect
            mask_type[b_idx_node, 1] = can_spawn
            
            if debug:
                # (ë””ë²„ê·¸ ì •ë³´ëŠ” b_idx_node[0] (0ë²ˆ ìƒ˜í”Œ) ê¸°ì¤€ìœ¼ë¡œë§Œ ìˆ˜ì§‘)
                if 0 in b_idx_node:
                    reasons["volt_ok"] = volt_ok[0]
                    reasons["cycle_ok"] = cycle_ok[0]
                    reasons["exclusive_ok"] = exclusive_ok[0]
                    reasons["power_seq_ok"] = power_seq_ok[0]
                    reasons["base_valid_parents"] = base_valid_parents[0]
                    reasons["thermal_current_ok"] = thermal_current_ok[0]
                    reasons["final_valid_parents"] = final_valid_parents[0]

        return {
            "mask_type": mask_type,
            "mask_connect": mask_connect,
            "mask_spawn": mask_spawn,
        }

        if debug:
            return {
                "mask_type": mask_type,
                "mask_connect": mask_connect,
                "mask_spawn": mask_spawn,
                "reasons": reasons # ë””ë²„ê·¸ ì •ë³´ ë°˜í™˜
            }
        else:
            return {
                "mask_type": mask_type,
                "mask_connect": mask_connect,
                "mask_spawn": mask_spawn,
            }

    # ---
    # ì„¹ì…˜ 6: ë§ˆìŠ¤í‚¹ í—¬í¼ í•¨ìˆ˜ (V6 ë¡œì§ ë²¡í„°í™”/ì ì‘)
    # ---

    def _trace_path_batch(self, start_nodes: torch.Tensor, adj_matrix_T: torch.Tensor) -> torch.Tensor:
        """ (V6 ê³„ìŠ¹) start_nodesì˜ ëª¨ë“  ì¡°ìƒ(ancestors)ì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜ (ì‚¬ì´í´ ë°©ì§€ìš©) """
        batch_size, num_nodes, _ = adj_matrix_T.shape
        path_mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)

        if start_nodes.numel() > 0:
            path_mask.scatter_(1, start_nodes.unsqueeze(-1), True)
        
        adj_matrix_T_float = adj_matrix_T.float()

        for _ in range(num_nodes):
            # (B,N,N) @ (B,N,1) -> (B,N)
            parents_mask = (adj_matrix_T_float @ path_mask.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~path_mask).sum() == 0: break
            path_mask |= parents_mask
            
        return path_mask

    def _get_exclusive_mask(self, 
                            td: TensorDict,           # ğŸ’¡ 'td' ì¸ì ì¶”ê°€
                            b_idx_node: torch.Tensor, # ğŸ’¡ 'b_idx_node' ì¸ì ì¶”ê°€
                            child_nodes: torch.Tensor
                            ) -> torch.Tensor:
        """ (V6 ê³„ìŠ¹) ë…ë¦½ ë ˆì¼(Exclusive Rail) ì œì•½ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± """
        # (tdì™€ b_idx_nodeì—ì„œ í•„ìš”í•œ í…ì„œë¥¼ ê°€ì ¸ì˜´)
        is_exclusive_mask_batch = td["is_exclusive_mask"][b_idx_node]
        adj_matrix_batch = td["adj_matrix"][b_idx_node]
        B_act, N_nodes = is_exclusive_mask_batch.shape
        
        # 1. Head(Child)ì˜ ìƒíƒœadj_matrix_T
        head_status = is_exclusive_mask_batch[torch.arange(B_act), child_nodes] # (B_act,)
        head_is_load = (self.node_type_tensor[child_nodes] == NODE_TYPE_LOAD) # (B_act,)

        # 2. Parent(í›„ë³´)ì˜ ìƒíƒœ
        parent_status = is_exclusive_mask_batch # (B_act, N_nodes)
        parent_is_exclusive = (parent_status > 0)
        
        # (B_act, N_nodes) - ë¶€ëª¨ê°€ ì´ë¯¸ ìì‹ì„ ê°€ì¡ŒëŠ”ì§€?
        parent_has_any_child = adj_matrix_batch.any(dim=-1)
        
        # 3. ìœ„ë°˜(Violation) ê·œì¹™ (True = ìœ„ë°˜ = ê¸ˆì§€)
        
        # ê·œì¹™ 1: Headê°€ 'Path'(2) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨
        # (B_act, 1) & (B_act, N_nodes) -> (B_act, N_nodes)
        violation_Rule1 = (head_status.unsqueeze(-1) == 2) & parent_has_any_child
        
        # ê·œì¹™ 2: Headê°€ 'Supplier Load'(1) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨
        violation_Rule2 = ((head_status == 1) & head_is_load).unsqueeze(-1) & parent_has_any_child
        
        # ê·œì¹™ 3: Headê°€ 'Normal'(0) ë˜ëŠ” 'Supplier IC'(1) -> ë¶€ëª¨ëŠ” Exclusiveì´ë©´ ì•ˆ ë¨
        violation_Rule3 = ((head_status == 0) | ((head_status == 1) & ~head_is_load)).unsqueeze(-1) & parent_is_exclusive
        
        violations = violation_Rule1 | violation_Rule2 | violation_Rule3
        
        # 4. ë°°í„°ë¦¬ëŠ” í•­ìƒ í—ˆìš©
        is_battery_mask = (self.arange_nodes.unsqueeze(0) == BATTERY_NODE_IDX)
        exclusive_ok = torch.logical_not(violations) | is_battery_mask
        
        return exclusive_ok

    def _get_power_sequence_mask(self,
                                 adj_matrix_batch: torch.Tensor,
                                 child_nodes: torch.Tensor,
                                 td: TensorDict,           
                                 b_idx_node: torch.Tensor  
                                 ) -> torch.Tensor:
        """ ì „ì› ì‹œí€€ì‹±(Power Sequence) ì œì•½ì¡°ê±´ ë§ˆìŠ¤í¬ ìƒì„± """
        B_act, N_nodes, _ = adj_matrix_batch.shape
        adj_matrix_T_batch = td["adj_matrix_T"][b_idx_node]
        candidate_mask = torch.ones(B_act, N_nodes, dtype=torch.bool, device=self.device)

        for j_idx, k_idx, f_flag in self.power_sequences:
            # Case 1: í˜„ì¬ childê°€ 'k' (jì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
            is_k_mask = (child_nodes == k_idx)
            if is_k_mask.any():
                b_idx_check = torch.where(is_k_mask)[0] # (B_k,)
                
                # 'j'ì˜ ë¶€ëª¨ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ê°€?
                parent_of_j_exists = adj_matrix_batch[b_idx_check, :, j_idx].any(dim=-1) # (B_k,)
                
                if parent_of_j_exists.any():
                    b_constr = b_idx_check[parent_of_j_exists] # (B_constr,)
                    
                    # 'j'ì˜ ë¶€ëª¨ ì¸ë±ìŠ¤ (V6ëŠ” argmax, V7ì€ Full AdjT)
                    parent_of_j_idx = adj_matrix_batch[b_constr, :, j_idx].long().argmax(-1) # (B_constr,)
                    
                    # 'j'ì˜ ë¶€ëª¨(parent_of_j)ì˜ ëª¨ë“  ì¡°ìƒ(ancestors)ì„ ì°¾ìŒ
                    anc_mask = self._trace_path_batch(parent_of_j_idx, adj_matrix_T_batch[b_constr])
                    anc_mask[:, BATTERY_NODE_IDX] = False # ë°°í„°ë¦¬ ì œì™¸
                    
                    # 'k'ì˜ ë¶€ëª¨ëŠ” 'j'ì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
                    candidate_mask[b_constr] &= ~anc_mask
                    
                    # (f=1) 'k'ì˜ ë¶€ëª¨ëŠ” 'j'ì˜ ë¶€ëª¨ì™€ ê°™ì„ ìˆ˜ ì—†ìŒ
                    if f_flag == 1:
                        same_parent_mask = (self.arange_nodes == parent_of_j_idx.unsqueeze(1))
                        candidate_mask[b_constr] &= ~same_parent_mask

            # Case 2: (V6ì™€ ë™ì¼) í˜„ì¬ childê°€ 'j' (kì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
            is_j_mask = (child_nodes == j_idx)
            if is_j_mask.any():
                b_idx_check = torch.where(is_j_mask)[0]
                parent_of_k_exists = adj_matrix_batch[b_idx_check, :, k_idx].any(dim=-1)
                
                if parent_of_k_exists.any():
                    b_constr = b_idx_check[parent_of_k_exists]
                    parent_of_k_idx = adj_matrix_batch[b_constr, :, k_idx].long().argmax(-1)
                    
                    anc_mask = self._trace_path_batch(parent_of_k_idx, adj_matrix_T_batch[b_constr])
                    anc_mask[:, BATTERY_NODE_IDX] = False
                    
                    # 'j'ì˜ ë¶€ëª¨ëŠ” 'k'ì˜ ì¡°ìƒì´ ë  ìˆ˜ ì—†ìŒ
                    candidate_mask[b_constr] &= ~anc_mask
                    
                    if f_flag == 1:
                        same_parent_mask = (self.arange_nodes == parent_of_k_idx.unsqueeze(1))
                        candidate_mask[b_constr] &= ~same_parent_mask
                        
        return candidate_mask

    def _get_thermal_current_mask(self,
                                  td: TensorDict,
                                  b_idx_node: torch.Tensor,
                                  child_nodes: torch.Tensor,
                                  base_valid_parents: torch.Tensor) -> torch.Tensor:
        """
        (V6 ê³„ìŠ¹) ì „ë¥˜/ë°œì—´ í•œê³„ë¥¼ ë§Œì¡±í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ë§ˆìŠ¤í¬ ìƒì„±.
        (ì—°ì‚° ë¹„ìš©ì´ ê°€ì¥ ë†’ì€ í•¨ìˆ˜)
        """
        
        # (B_act, N_max)
        thermal_current_ok = base_valid_parents.clone()
        
        # ì‹œë®¬ë ˆì´ì…˜ ì²­í¬ í¬ê¸° (ë©”ëª¨ë¦¬/ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„)
        SIM_CHUNK_SIZE = 32 
        
        B_act, N_nodes = base_valid_parents.shape
        
        base_nodes = td["nodes"][b_idx_node]
        base_adj_matrix = td["adj_matrix"][b_idx_node]
        base_adj_matrix_T = td["adj_matrix_T"][b_idx_node]
        
        # ë§ˆì§„(Margin) ê°’ ë¯¸ë¦¬ ë¡œë“œ
        margin_I = float(self.generator.config.constraints.get("current_margin", 0.0))
        margin_T = float(self.generator.config.constraints.get("thermal_margin_percent", 0.0))
        
        # (N_max,) - IC íƒ€ì… ë§ˆìŠ¤í¬
        ic_mask_1d = (self.node_type_tensor == NODE_TYPE_IC)
        
        # (N_max) í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì‹œë®¬ë ˆì´ì…˜
        for chunk_start in range(0, N_nodes, SIM_CHUNK_SIZE):
            chunk_end = min(chunk_start + SIM_CHUNK_SIZE, N_nodes)
            parent_indices_in_chunk = torch.arange(chunk_start, chunk_end, device=self.device)
            
            # (B_act, N_chunk) - ì´ë²ˆ ì²­í¬ì—ì„œ ì‹œë®¬ë ˆì´ì…˜í•  (ë°°ì¹˜, ë¶€ëª¨) í›„ë³´
            candidates_in_chunk_mask = base_valid_parents[:, chunk_start:chunk_end]
            
            # (N_sim,) - (B_act ê¸°ì¤€ ì¸ë±ìŠ¤, ë¡œì»¬ ë¶€ëª¨ ì¸ë±ìŠ¤)
            b_idx_sim_chunk, p_idx_sim_chunk_local = candidates_in_chunk_mask.nonzero(as_tuple=True)
            
            if b_idx_sim_chunk.numel() == 0:
                continue # ì‹œë®¬ë ˆì´ì…˜í•  í›„ë³´ ì—†ìŒ
            
            N_sim = b_idx_sim_chunk.numel()
            
            # 1. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ì¤€ë¹„ (N_sim,)
            sim_nodes = base_nodes[b_idx_sim_chunk]
            sim_adj_matrix = base_adj_matrix[b_idx_sim_chunk].clone()
            sim_adj_matrix_T = base_adj_matrix_T[b_idx_sim_chunk].clone()
            sim_child_nodes = child_nodes[b_idx_sim_chunk]
            
            # (N_sim,) - ì‹¤ì œ ë¶€ëª¨ ë…¸ë“œ ì¸ë±ìŠ¤
            sim_parent_indices_global = parent_indices_in_chunk[p_idx_sim_chunk_local]
            
            # 2. (ê°€ìƒ) ì—£ì§€ ì¶”ê°€: (parent) -> (child)
            sim_rows = torch.arange(N_sim, device=self.device)
            sim_adj_matrix[sim_rows, sim_parent_indices_global, sim_child_nodes] = True
            sim_adj_matrix_T[sim_rows, sim_child_nodes, sim_parent_indices_global] = True

            # 3. ğŸš€ íŠ¸ë¦¬ ì „ì²´ ë¶€í•˜ ì‹œë®¬ë ˆì´ì…˜
            (final_i_out, power_loss, junction_temp) = self._calculate_tree_loads(
                sim_nodes, 
                sim_adj_matrix,
                sim_adj_matrix_T # ğŸ’¡ T ë§¤íŠ¸ë¦­ìŠ¤ ì „ë‹¬
            )

            # 4. ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ê²€ì¦
            i_limit_raw = sim_nodes[..., FEATURE_INDEX["i_limit"]]
            t_max_raw   = sim_nodes[..., FEATURE_INDEX["t_junction_max"]]
            
            i_limit = i_limit_raw * (1.0 - margin_I)
            t_max   = t_max_raw   # (V6ëŠ” T_maxì— ë§ˆì§„ ì ìš© ì•ˆ í•¨, V7 commonì€ ì ìš©í•¨. V6 ê³„ìŠ¹)
            
            # (N_sim, N_max)
            current_check_ok = (final_i_out <= i_limit + 1e-6)
            temp_check_ok = (junction_temp <= t_max + 1e-6)
            
            # (N_sim, N_max)
            all_checks_ok = current_check_ok & temp_check_ok
            
            # (N_sim, N_max) - ICê°€ ì•„ë‹Œ ë…¸ë“œëŠ” í•­ìƒ OK
            ic_mask_sim = ic_mask_1d.expand(N_sim, -1)
            
            # (N_sim,) - (ëª¨ë“  ICê°€ OK)
            is_valid_simulation = (all_checks_ok | ~ic_mask_sim).all(dim=-1)

            # 5. ì‹¤íŒ¨í•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ (B_act, N_max) ë§ˆìŠ¤í¬ì— ë°˜ì˜
            failed_sim_mask = ~is_valid_simulation
            if failed_sim_mask.any():
                b_idx_failed = b_idx_sim_chunk[failed_sim_mask]
                p_idx_failed_global = sim_parent_indices_global[failed_sim_mask]
                
                thermal_current_ok[b_idx_failed, p_idx_failed_global] = False
                
        return thermal_current_ok

    # ---
    # ì„¹ì…˜ 7: ê³„ì‚° í—¬í¼ í•¨ìˆ˜ (V6 ë¡œì§ ë²¡í„°í™”/ì ì‘)
    # ---

    def _calculate_tree_loads(self, 
                              nodes_tensor: torch.Tensor, 
                              adj_matrix: torch.Tensor,
                              adj_matrix_T: torch.Tensor
                              ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """ (V6 ê³„ìŠ¹) Adjacency Matrixë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë¦¬ ì „ì²´ì˜ ì „ë¥˜/ì „ë ¥ì†ì‹¤/ì˜¨ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. """
        
        batch_size, num_nodes, _ = nodes_tensor.shape
        
        # 1. ì´ˆê¸° ìˆ˜ìš” = Loadì˜ í™œì„± ì „ë¥˜
        current_demands = nodes_tensor[..., FEATURE_INDEX["current_active"]].clone()
        
        # Loadê°€ ì•„ë‹Œ ë…¸ë“œëŠ” ì´ˆê¸° ìˆ˜ìš”ê°€ 0
        load_mask_1d = (self.node_type_tensor == NODE_TYPE_LOAD) # (N_max,)
        current_demands[:, ~load_mask_1d] = 0.0
        
        adj_matrix_float = adj_matrix.float()
        adj_matrix_T_float = adj_matrix_T.float()

        # (IC íƒ€ì…, LDO/Buck)
        ic_type = nodes_tensor[..., FEATURE_INDEX["ic_type_idx"]]
        ldo_mask_b = torch.isclose(ic_type, torch.tensor(1.0, device=ic_type.device))
        buck_mask_b = torch.isclose(ic_type, torch.tensor(2.0, device=ic_type.device))
        
        op_current = nodes_tensor[..., FEATURE_INDEX["op_current"]]
        vout = nodes_tensor[..., FEATURE_INDEX["vout_min"]] # (ê³ ì • Vout)
        vin = nodes_tensor[..., FEATURE_INDEX["vin_min"]]  # (ê³ ì • Vin)
        safe_vin = torch.where(vin > 0, vin, 1e-6)
        eff = 0.9 # (ê³ ì • íš¨ìœ¨)

        # 2. ì „ë¥˜ ì „íŒŒ (Bottom-up)
        # (i_in_totalì€ (B, N_max)ë¡œ, ê° ë…¸ë“œê°€ *ì†Œë¹„*í•˜ëŠ” ì´ ì „ë¥˜)
        i_in_total = current_demands.clone() 

        for _ in range(num_nodes):
            # i_out (B, N_max) = ì´ ë…¸ë“œê°€ ìì‹ë“¤ì—ê²Œ *ê³µê¸‰*í•´ì•¼ í•˜ëŠ” ì´ ì „ë¥˜
            # i_out = (B,N,N) @ (B,N,1) -> (B,N)
            i_out = (adj_matrix_float @ i_in_total.unsqueeze(-1)).squeeze(-1)            

            # I_in_ldo/buck (B, N_max) = ì´ ë…¸ë“œê°€ *ê³µê¸‰*í•˜ê¸° ìœ„í•´ *ì†Œë¹„*í•´ì•¼ í•˜ëŠ” ì „ë¥˜
            i_in_ldo = i_out + op_current
            
            # Buck ì…ë ¥ ì „ë¥˜: I_in = P_out / (Eff * V_in) + I_op
            p_out_buck = vout * i_out
            i_in_buck = (p_out_buck / eff) / safe_vin + op_current
            
            # (B, N_max) - IC ë…¸ë“œë“¤ì˜ ì´ ì…ë ¥ ìˆ˜ìš”
            new_ic_demands = torch.zeros_like(i_in_total)
            new_ic_demands[ldo_mask_b] = i_in_ldo[ldo_mask_b]
            new_ic_demands[buck_mask_b] = i_in_buck[buck_mask_b]

            new_i_in_total = current_demands + new_ic_demands
            if torch.allclose(i_in_total, new_i_in_total, atol=1e-8):
                break
            i_in_total = new_i_in_total

        i_out = (adj_matrix_float @ i_in_total.unsqueeze(-1)).squeeze(-1)
            
        # 3. ìµœì¢… ì†ì‹¤ ë° ì˜¨ë„ ê³„ì‚°
        power_loss = self._calculate_power_loss(
            nodes_tensor, i_out, ldo_mask_b, buck_mask_b
        )
        theta_ja = nodes_tensor[..., FEATURE_INDEX["theta_ja"]]
        ambient_temp = self.generator.config.constraints.get("ambient_temperature", 25.0)
        junction_temp = ambient_temp + power_loss * theta_ja
        
        return i_out, power_loss, junction_temp

    def _calculate_power_loss(self, 
                              ic_node_features: torch.Tensor, 
                              i_out: torch.Tensor,
                              ldo_mask: torch.Tensor,
                              buck_mask: torch.Tensor
                              ) -> torch.Tensor:
        """ (V6 ê³„ìŠ¹) I_outì„ ê¸°ë°˜ìœ¼ë¡œ ICì˜ ì „ë ¥ ì†ì‹¤(P_loss)ì„ ê³„ì‚°í•©ë‹ˆë‹¤. """
        
        vin = ic_node_features[..., FEATURE_INDEX["vin_min"]]
        vout = ic_node_features[..., FEATURE_INDEX["vout_min"]]
        op_current = ic_node_features[..., FEATURE_INDEX["op_current"]]
        power_loss = torch.zeros_like(i_out)
        
        # LDO: P_loss = (V_in - V_out) * I_out + V_in * I_op
        if ldo_mask.any():
            power_loss[ldo_mask] = (vin[ldo_mask] - vout[ldo_mask]) * i_out[ldo_mask] + \
                                   vin[ldo_mask] * op_current[ldo_mask]
        
        # Buck: P_loss = P_out * (1/Eff - 1) + V_in * I_op
        if buck_mask.any():
            p_out_buck = vout[buck_mask] * i_out[buck_mask]
            eff = 0.9 # (ê³ ì • íš¨ìœ¨)
            conversion_loss = (p_out_buck / eff) - p_out_buck
            power_loss[buck_mask] = conversion_loss + vin[buck_mask] * op_current[buck_mask]
            
        return power_loss

    def _calculate_total_sleep_current(self, td: TensorDict) -> torch.Tensor:
        """ (V6 ê³„ìŠ¹) ì•”ì „ë¥˜(Sleep Current) ì œì•½ì¡°ê±´ì„ ê²€ì‚¬í•©ë‹ˆë‹¤. """
        
        batch_size, num_nodes, _ = td["nodes"].shape
        adj_matrix = td["adj_matrix"].float()
        adj_matrix_T = td["adj_matrix_T"].float() # ğŸ’¡ (c, p) -> (p, c)

        # 1. "Always-On" ìƒíƒœ ì „íŒŒ (Load -> Battery)
        always_on_loads = (td["nodes"][..., FEATURE_INDEX["always_on_in_sleep"]] == 1.0)
        always_on_nodes = always_on_loads.clone()
        always_on_nodes[:, BATTERY_NODE_IDX] = True
        
        for _ in range(num_nodes):
            parents_mask = (adj_matrix_T @ always_on_nodes.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~always_on_nodes).sum() == 0: break
            always_on_nodes |= parents_mask
        
        # 2. IC ìì²´ ì•”ì „ë¥˜ ì†Œëª¨ (3-State)
        is_ao = always_on_nodes
        is_used = td["is_used_ic_mask"]
        parent_is_ao = (adj_matrix_T @ is_ao.float().unsqueeze(-1)).squeeze(-1).bool()

        op_current = td["nodes"][..., FEATURE_INDEX["op_current"]]
        quiescent_current = td["nodes"][..., FEATURE_INDEX["quiescent_current"]]
        shutdown_current = td["nodes"][..., FEATURE_INDEX["shutdown_current"]]
        
        use_ishut_current = torch.where(shutdown_current > 1e-9, shutdown_current, quiescent_current)
        ic_self_sleep = torch.zeros(batch_size, num_nodes, device=self.device)
        
        ic_self_sleep[is_ao & is_used] = op_current[is_ao & is_used]
        ic_self_sleep[~is_ao & is_used & parent_is_ao] = use_ishut_current[~is_ao & is_used & parent_is_ao]

        # 3. Load ì•”ì „ë¥˜ ì†Œëª¨
        load_sleep_draw_base = td["nodes"][..., FEATURE_INDEX["current_sleep"]].clone()
        load_sleep_draw = load_sleep_draw_base * always_on_nodes.float()
        load_sleep_draw[~always_on_nodes] = 0.0

        # 4. ì „ë¥˜ ìˆ˜ìš” ì „íŒŒ (LDO/Buck íš¨ìœ¨ ì ìš©)
        current_demands_sleep = load_sleep_draw + ic_self_sleep
        
        # (B, N) ëª¨ì–‘ì˜ LDO/Buck ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        # (B, N)
        ic_type = td["nodes"][..., FEATURE_INDEX["ic_type_idx"]]
        
        # (B, N)
        ldo_mask_b = torch.isclose(ic_type, torch.tensor(1.0, device=ic_type.device))
        
        # (B, N)
        buck_mask_b = torch.isclose(ic_type, torch.tensor(2.0, device=ic_type.device))

        # (ì°¸ê³ : ic_mask_b_nì€ ì´ í•¨ìˆ˜ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì‚­ì œí•˜ê±°ë‚˜ (B, N)ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•¨)
        # (B, N)
        ic_mask_b_n = (self.node_type_tensor == NODE_TYPE_IC).expand(batch_size, -1)        
        
        vin = td["nodes"][..., FEATURE_INDEX["vin_min"]]
        vout = td["nodes"][..., FEATURE_INDEX["vout_min"]]
        safe_vin = torch.where(vin > 0, vin, 1e-6)
        eff_sleep = 0.35 # (ê³ ì • íš¨ìœ¨)
        
        for _ in range(num_nodes):
            i_out_sleep = (adj_matrix_T.transpose(-1, -2) @ current_demands_sleep.unsqueeze(-1)).squeeze(-1)
            
            new_demands_sleep = load_sleep_draw + ic_self_sleep
            
            # LDO: I_in = I_out
            new_demands_sleep[ldo_mask_b] += i_out_sleep[ldo_mask_b]
            
            # Buck: I_in = P_out / (Eff * V_in)
            p_out_sleep_buck = vout[buck_mask_b] * i_out_sleep[buck_mask_b]
            p_in_sleep_buck = p_out_sleep_buck / eff_sleep
            i_in_sleep_buck = p_in_sleep_buck / safe_vin[buck_mask_b]
            new_demands_sleep[buck_mask_b] += i_in_sleep_buck
            
            if torch.allclose(current_demands_sleep, new_demands_sleep, atol=1e-8):
                break
            current_demands_sleep = new_demands_sleep

        # 5. ë°°í„°ë¦¬ ì´ ì•”ì „ë¥˜
        battery_children_mask = adj_matrix[:, BATTERY_NODE_IDX, :]
        total_sleep_current = (current_demands_sleep * battery_children_mask).sum(dim=1)
        
        return total_sleep_current # (B,)